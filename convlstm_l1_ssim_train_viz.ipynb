{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ConvLSTM (CLSTM) Notebook\n",
        "\n",
        "This notebook packages:\n",
        "- L1 + SSIM loss (external library)\n",
        "- Training loop with loss history\n",
        "- Loss-epoch plot\n",
        "- Prediction visualization\n",
        "- Hooks to plug in your own `Task1Dataset`\n",
        "\n",
        "**Required variable names:** `train_ds, val_ds, train_loader, val_loader`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ed5ab07",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: basics\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'model'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-583951522.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cell 2: import model code (keep repo structure)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Assumes you are running in the repo root (same folder as model.py, net_params.py, etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderDecoderConvLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnet_params\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvlstm_encoder_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvlstm_decoder_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: import model code (keep repo structure)\n",
        "# Assumes you are running in the repo root (same folder as model.py, net_params.py, etc.)\n",
        "from model import EncoderDecoderConvLSTM\n",
        "from net_params import convlstm_encoder_params, convlstm_decoder_params\n",
        "\n",
        "model = EncoderDecoderConvLSTM(\n",
        "    convlstm_encoder_params,\n",
        "    convlstm_decoder_params,\n",
        ").to(device)\n",
        "\n",
        "print(model.__class__.__name__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: SSIM external lib\n",
        "# If not installed, uncomment the next line:\n",
        "# !pip -q install pytorch-msssim\n",
        "\n",
        "from pytorch_msssim import ssim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: L1 + SSIM Loss (works with z-score by using dynamic data_range)\n",
        "class L1SSIMLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.8, ssim_win_size=11, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.l1 = nn.L1Loss()\n",
        "        self.win_size = ssim_win_size\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        # pred/target: (B,T,C,H,W) or (B,C,H,W)\n",
        "        l1_loss = self.l1(pred, target)\n",
        "\n",
        "        # Flatten time into batch for SSIM\n",
        "        if pred.dim() == 5:\n",
        "            B, T, C, H, W = pred.shape\n",
        "            pred_ = pred.reshape(B * T, C, H, W)\n",
        "            tgt_  = target.reshape(B * T, C, H, W)\n",
        "        else:\n",
        "            pred_ = pred\n",
        "            tgt_  = target\n",
        "\n",
        "        # Dynamic data_range for z-score\n",
        "        vmin = torch.min(torch.min(pred_.detach()), torch.min(tgt_.detach()))\n",
        "        vmax = torch.max(torch.max(pred_.detach()), torch.max(tgt_.detach()))\n",
        "        data_range = (vmax - vmin).clamp_min(self.eps)\n",
        "\n",
        "        ssim_val = ssim(\n",
        "            pred_, tgt_,\n",
        "            data_range=data_range,\n",
        "            size_average=True,\n",
        "            win_size=self.win_size\n",
        "        )\n",
        "        ssim_loss = 1.0 - ssim_val\n",
        "\n",
        "        return self.alpha * l1_loss + (1.0 - self.alpha) * ssim_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plug in your dataset\n",
        "\n",
        "Choose one of the following.\n",
        "\n",
        "### Option A: Your Task1Dataset (recommended)\n",
        "\n",
        "⚠️ You previously hit: `Task1Dataset.__init__() got multiple values for argument 'log_min'`.\n",
        "That usually means `log_min` is already the 3rd positional parameter, so pass `log_min/log_max` positionally (do **not** repeat keyword).\n",
        "\n",
        "### Option B: MovingMNIST (repo demo)\n",
        "\n",
        "If you just want to test the pipeline first, you can use MovingMNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "hf_hub_download(\n",
        "    repo_id=\"benmoseley/ese-dl-2025-26-group-project\",\n",
        "    filename=\"train.h5\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=\"data\",\n",
        ")\n",
        "hf_hub_download(\n",
        "    repo_id=\"benmoseley/ese-dl-2025-26-group-project\",\n",
        "    filename=\"events.csv\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=\"data\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b646e90",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "print(\"CWD:\", os.getcwd())\n",
        "print(\"data/ contains:\", os.listdir(\"data\"))\n",
        "\n",
        "H5_PATH = \"data/train.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf3cd32",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect file structure (storm IDs)\n",
        "with h5py.File(H5_PATH, \"r\") as f:\n",
        "    storm_ids_all = sorted(list(f.keys()))\n",
        "    print(\"Number of storms:\", len(storm_ids_all))\n",
        "    print(\"First 10 storm IDs:\", storm_ids_all[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a8b0f25",
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Helpers: (H, W, T) -> (T, H, W) and Task-1 slicing\n",
        "def vil_to_THW(vil_hwT: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convert raw VIL from (H, W, T) to (T, H, W).\n",
        "    The dataset stores VIL as (384, 384, 36) = (H, W, T).\n",
        "    We use time-first everywhere: (T, H, W).\n",
        "    \"\"\"\n",
        "    return np.transpose(vil_hwT, (2, 0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4003848f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_task1_pair_THW(vil_THW: np.ndarray, T_in: int = 12, T_out: int = 12):\n",
        "    \"\"\"\n",
        "    Task 1:\n",
        "      Input  = first 12 frames\n",
        "      Target = next 12 frames\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    vil_THW : np.ndarray, shape (T_total, H, W)  (T_total=36)\n",
        "    T_in    : int\n",
        "    T_out   : int\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_THW : np.ndarray, shape (T_in,  H, W)\n",
        "    Y_THW : np.ndarray, shape (T_out, H, W)\n",
        "    \"\"\"\n",
        "    X = vil_THW[:T_in]\n",
        "    Y = vil_THW[T_in:T_in + T_out]\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4256c285",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Train/val split by storm ID (prevents leakage)\n",
        "ids_train, ids_val = train_test_split(\n",
        "    storm_ids_all,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "print(\"Train storms:\", len(ids_train), \"Val storms:\", len(ids_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81344d33",
      "metadata": {},
      "outputs": [],
      "source": [
        "#DataLoaders\n",
        "#    Tip: 384x384 is big. Start small (batch_size=4/8). Increase later if stable.\n",
        "# -------------------------\n",
        "use_pin_memory = torch.cuda.is_available()\n",
        "\n",
        "train_ds = Task1StormDataset(H5_PATH, ids_train, train_mean, train_std, T_in=12, T_out=12)\n",
        "val_ds   = Task1StormDataset(H5_PATH, ids_val,   train_mean, train_std, T_in=12, T_out=12)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  num_workers=0, pin_memory=use_pin_memory)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=0, pin_memory=use_pin_memory)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "395be67e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#PyTorch Dataset (VIL only, Z-normalized) — outputs (T,1,H,W)\n",
        "#    Key points:\n",
        "#      - reads only (T_in + T_out) frames (24) to save RAM\n",
        "#      - normalizes BOTH X and Y using TRAIN mean/std\n",
        "#      - lazy-opens HDF5 file once (faster than opening every __getitem__)\n",
        "# -------------------------\n",
        "class Task1StormDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Returns (X, Y, storm_id) for Task 1.\n",
        "\n",
        "    Shapes:\n",
        "      X: (T_in,  1, H, W)\n",
        "      Y: (T_out, 1, H, W)\n",
        "    \"\"\"\n",
        "    def __init__(self, h5_path: str, storm_ids, mean: float, std: float, T_in: int = 12, T_out: int = 12):\n",
        "        self.h5_path = h5_path\n",
        "        self.storm_ids = list(storm_ids)\n",
        "\n",
        "        self.mean = float(mean)\n",
        "        self.std = float(std) + 1e-6  # avoid divide-by-zero\n",
        "\n",
        "        self.T_in = int(T_in)\n",
        "        self.T_out = int(T_out)\n",
        "\n",
        "        self._file = None  # lazy open\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.storm_ids)\n",
        "\n",
        "    def _get_file(self):\n",
        "        if self._file is None:\n",
        "            self._file = h5py.File(self.h5_path, \"r\")\n",
        "        return self._file\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sid = self.storm_ids[idx]\n",
        "        f = self._get_file()\n",
        "\n",
        "        # load ONLY frames we need: first (T_in + T_out)\n",
        "        T_needed = self.T_in + self.T_out\n",
        "        vil_hwT = f[f\"{sid}/vil\"][:, :, :T_needed].astype(np.float32)  # (H,W,24)\n",
        "\n",
        "        vil_THW = np.transpose(vil_hwT, (2, 0, 1))  # (24,H,W)\n",
        "\n",
        "        X_THW = vil_THW[:self.T_in]                           # (12,H,W)\n",
        "        Y_THW = vil_THW[self.T_in:self.T_in + self.T_out]     # (12,H,W)\n",
        "\n",
        "        # Z-normalize using TRAIN stats\n",
        "        X_THW = (X_THW - self.mean) / self.std\n",
        "        Y_THW = (Y_THW - self.mean) / self.std\n",
        "\n",
        "        # Convert to torch tensors and add channel dim -> (T,1,H,W)\n",
        "        X = torch.from_numpy(X_THW).unsqueeze(1)  # (12,1,H,W)\n",
        "        Y = torch.from_numpy(Y_THW).unsqueeze(1)  # (12,1,H,W)\n",
        "\n",
        "        return X, Y, sid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5B: MovingMNIST demo (optional)\n",
        "# Comment out if you use Task1Dataset\n",
        "\n",
        "# from data.mm import MovingMNIST\n",
        "# train_ds = MovingMNIST(is_train=True, root=\"data/\", n_frames_input=10, n_frames_output=10, num_objects=[3])\n",
        "# val_ds   = MovingMNIST(is_train=False, root=\"data/\", n_frames_input=10, n_frames_output=10, num_objects=[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: DataLoader (keep variable names)\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        ")\n",
        "print(\"train batches:\", len(train_loader), \"val batches:\", len(val_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Loss & optimizer (L1 + SSIM)\n",
        "loss_fn = L1SSIMLoss(alpha=0.8, ssim_win_size=11)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Train / Eval loops (history for plots)\n",
        "@torch.no_grad()\n",
        "def _ensure_tensor(x):\n",
        "    # Some repos return (pred, states) etc. This keeps only the tensor.\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        return x[0]\n",
        "    return x\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, loss_fn, device):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    for inputs, targets in loader:\n",
        "        inputs  = inputs.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = _ensure_tensor(model(inputs))\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += loss.item()\n",
        "    return total / max(1, len(loader))\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    for inputs, targets in loader:\n",
        "        inputs  = inputs.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        outputs = _ensure_tensor(model(inputs))\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        total += loss.item()\n",
        "    return total / max(1, len(loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Fit\n",
        "history = {\"train_loss\": [], \"val_loss\": []}\n",
        "num_epochs = 20\n",
        "\n",
        "best_val = float(\"inf\")\n",
        "save_path = \"checkpoints/best_convlstm_ed.pt\"\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    tr = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
        "    va = eval_one_epoch(model, val_loader, loss_fn, device)\n",
        "\n",
        "    history[\"train_loss\"].append(tr)\n",
        "    history[\"val_loss\"].append(va)\n",
        "\n",
        "    if va < best_val:\n",
        "        best_val = va\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f\"Epoch {epoch:03d}/{num_epochs:03d} | train={tr:.6f} | val={va:.6f} | best_val={best_val:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10: loss-epoch plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history[\"train_loss\"], label=\"train\")\n",
        "plt.plot(history[\"val_loss\"], label=\"val\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss (L1 + SSIM)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: Prediction visualization (GT vs Pred frames)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "@torch.no_grad()\n",
        "def visualize_prediction(model, loader, device, channel_idx=0, max_frames=12):\n",
        "    model.eval()\n",
        "    inputs, targets = next(iter(loader))\n",
        "    inputs  = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    preds = _ensure_tensor(model(inputs))\n",
        "\n",
        "    # pick first sample: (T,C,H,W)\n",
        "    pred0 = preds[0]\n",
        "    tgt0  = targets[0]\n",
        "\n",
        "    T = min(int(pred0.shape[0]), int(max_frames))\n",
        "    C = int(pred0.shape[1])\n",
        "    ch = min(int(channel_idx), C - 1)\n",
        "\n",
        "    pred_seq = pred0[:T, ch].detach().cpu().numpy()\n",
        "    tgt_seq  = tgt0[:T,  ch].detach().cpu().numpy()\n",
        "\n",
        "    plt.figure(figsize=(2*T, 4))\n",
        "    for t in range(T):\n",
        "        plt.subplot(2, T, t + 1)\n",
        "        plt.imshow(tgt_seq[t])\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"GT t={t}\")\n",
        "\n",
        "        plt.subplot(2, T, T + t + 1)\n",
        "        plt.imshow(pred_seq[t])\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"Pred t={t}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# For your dataset: if C==1, channel_idx must be 0\n",
        "visualize_prediction(model, val_loader, device, channel_idx=0, max_frames=12)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
